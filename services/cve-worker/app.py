import os
import time
import logging
import requests
import psycopg2
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime, timedelta

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤ ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_DIR = os.path.join(BASE_DIR, "../../logs")
os.makedirs(LOG_DIR, exist_ok=True)
LOG_FILE = os.path.join(LOG_DIR, "cve_worker.log")

logging.basicConfig(
    level=os.getenv("LOG_LEVEL", "INFO"),
    format="[%(levelname)s] %(asctime)s | %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE, encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
DB_URL = os.getenv("DB_URL", "postgresql://postgres:postgres@db:5432/cve")
NVD_API = "https://services.nvd.nist.gov/rest/json/cves/2.0"
MAX_DB_RETRIES = 10
DB_RETRY_DELAY = 5  # —Å–µ–∫—É–Ω–¥

# --- –§—É–Ω–∫—Ü–∏–∏ ---
def wait_for_db():
    """–û–∂–∏–¥–∞–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    for attempt in range(MAX_DB_RETRIES):
        try:
            conn = psycopg2.connect(DB_URL)
            conn.close()
            logger.info("‚úÖ Database is ready")
            return
        except psycopg2.OperationalError:
            logger.warning(f"‚è≥ DB not ready, retrying in {DB_RETRY_DELAY}s... ({attempt + 1}/{MAX_DB_RETRIES})")
            time.sleep(DB_RETRY_DELAY)
    logger.error("‚ùå DB is not available after multiple attempts. Exiting.")
    raise RuntimeError("Database unavailable")


def fetch_cves():
    """–ó–∞–≥—Ä—É–∑–∫–∞ CVE –∏–∑ NVD API"""
    logger.info("üì° Fetching CVEs from NVD...")

    # end_date = —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è - 1 —á–∞—Å (—á—Ç–æ–±—ã –Ω–µ —É—Ö–æ–¥–∏—Ç—å –≤ –±—É–¥—É—â–µ–µ)
    end_date = datetime.utcnow() - timedelta(hours=1)
    start_date = end_date - timedelta(days=7)

    url = (
        f"{NVD_API}"
        f"?pubStartDate={start_date.strftime('%Y-%m-%dT%H:%M:%S.000')}Z"
        f"&pubEndDate={end_date.strftime('%Y-%m-%dT%H:%M:%S.000')}Z"
    )

    headers = {}
    api_key = os.getenv("NVD_API_KEY")
    if api_key:
        headers["apiKey"] = api_key

    try:
        resp = requests.get(url, headers=headers, timeout=30)

        if resp.status_code >= 500:
            logger.error(f"‚ö†Ô∏è NVD server error {resp.status_code}, retry later")
            return

        resp.raise_for_status()
        data = resp.json()
        vulns = data.get("vulnerabilities", [])
        logger.info(f"‚úÖ Fetched {len(vulns)} CVEs")

        if vulns:
            save_to_db(vulns)

    except requests.RequestException as e:
        logger.error(f"‚ùå Error fetching CVEs: {e}")


def save_to_db(vulns):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º CVE –≤ —Ç–∞–±–ª–∏—Ü–µ vulnerabilities"""
    for attempt in range(MAX_DB_RETRIES):
        try:
            conn = psycopg2.connect(DB_URL)
            break
        except psycopg2.OperationalError:
            logger.warning(f"DB not ready, retrying in {DB_RETRY_DELAY}s... ({attempt + 1}/{MAX_DB_RETRIES})")
            time.sleep(DB_RETRY_DELAY)
    else:
        logger.error("‚ùå DB is not available after multiple attempts. Exiting.")
        return

    cur = conn.cursor()

    new_count = 0
    updated_count = 0

    for item in vulns:
        cve = item["cve"]
        cve_id = cve["id"]
        desc = cve["descriptions"][0]["value"] if cve.get("descriptions") else ""

        # --- –¥–∞—Ç—ã ---
        published = cve.get("published")
        updated = cve.get("lastModified")
        try:
            published_dt = datetime.fromisoformat(published.replace("Z", "+00:00")) if published else None
            updated_dt = datetime.fromisoformat(updated.replace("Z", "+00:00")) if updated else None
        except Exception:
            published_dt, updated_dt = None, None

        cvss_v3_score = None
        cvss_v3_severity = None
        metrics = cve.get("metrics", {})
        if "cvssMetricV31" in metrics:
            cvss_v3_score = metrics["cvssMetricV31"][0]["cvssData"]["baseScore"]
            cvss_v3_severity = metrics["cvssMetricV31"][0]["cvssData"]["baseSeverity"]

        cur.execute("""
            INSERT INTO vulnerabilities (cve_id, description, published_at, updated_at, cvss_v3_score, cvss_v3_severity)
            VALUES (%s, %s, %s, %s, %s, %s)
            ON CONFLICT (cve_id)
            DO UPDATE SET
                description = EXCLUDED.description,
                published_at = EXCLUDED.published_at,
                updated_at = EXCLUDED.updated_at,
                cvss_v3_score = EXCLUDED.cvss_v3_score,
                cvss_v3_severity = EXCLUDED.cvss_v3_severity
            RETURNING xmax;
        """, (cve_id, desc, published_dt, updated_dt, cvss_v3_score, cvss_v3_severity))

        xmax = cur.fetchone()[0]
        if xmax == 0:
            new_count += 1
        else:
            updated_count += 1

    conn.commit()
    cur.close()
    conn.close()
    logger.info(f"üíæ Processed {len(vulns)} CVEs: {new_count} new, {updated_count} updated")


# --- –û—Å–Ω–æ–≤–Ω–æ–π –±–ª–æ–∫ ---
if __name__ == "__main__":
    wait_for_db()

    scheduler = BackgroundScheduler()
    scheduler.add_job(fetch_cves, "interval", hours=int(os.getenv("UPDATE_INTERVAL_HOURS", 4)))
    scheduler.start()

    fetch_cves()  # –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞

    logger.info("üöÄ CVE Worker started, waiting for jobs...")

    # –¥–µ—Ä–∂–∏–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∂–∏–≤—ã–º
    try:
        while True:
            time.sleep(60)
    except KeyboardInterrupt:
        logger.info("üõë Worker stopped manually")
